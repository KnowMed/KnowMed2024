{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a8ffcd",
   "metadata": {},
   "source": [
    "This notebook shows the testing of alternative NLP techniques considered. FinalNLP is the code for the final NLP pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb2ced5",
   "metadata": {},
   "source": [
    "# Testing NER and word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63add999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing NER as a means to detect if the symptom is present in the record \n",
    "\n",
    "import spacy\n",
    "\n",
    "# Load spaCy's English language model\n",
    "#nlp = spacy.load(\"en_core_web_sm\") \n",
    "#nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "#These did not cater for medical entities\n",
    "\n",
    "# Clinical record text\n",
    "clinical_record = \"6. Type 2 diabetes mellitus. 7. Aortic stenosis. 8. Mild asthma. 9. History of atrial fibrillation. 10. History of pneumonectomy in 1999 for tuberculosis. 11. History of AV block. 12. Gastroesophageal reflux. 13. Glaucoma. 14. Hypothyroidism. 15. Osteoarthritis. 16. Osteopenia. 17. Mild pulmonary hypertension. 18. History of squamous-cell carcinoma of the left anterior thigh status post excision in 2006.\"\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(clinical_record)\n",
    "\n",
    "# Extract entities (medical conditions)\n",
    "medical_conditions = [ent.text.lower() for ent in doc.ents if ent.label_ == \"MEDICAL_CONDITION\"]\n",
    "\n",
    "# Check if \"asthma\" is mentioned\n",
    "if \"asthma\" in medical_conditions:\n",
    "    print(\"The patient has asthma.\")\n",
    "else:\n",
    "    print(\"The patient does not have asthma.\")\n",
    "\n",
    "# Print the detected medical conditions\n",
    "print(\"Detected Medical Conditions:\")\n",
    "for condition in medical_conditions:\n",
    "    print(\"-\", condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f7712",
   "metadata": {},
   "source": [
    "Using spacy for Named Entity Recognition to identify and extract medical conditions mentioned in the clinical record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc46514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Med7 word embedding\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "med7 = spacy.load(\"en_core_med7_lg\")\n",
    "\n",
    "# create distinct colours for labels\n",
    "col_dict = {}\n",
    "seven_colours = ['#e6194B', '#3cb44b', '#ffe119', '#ffd8b1', '#f58231', '#f032e6', '#42d4f4']\n",
    "for label, colour in zip(med7.pipe_labels['ner'], seven_colours):\n",
    "    col_dict[label] = colour\n",
    "\n",
    "options = {'ents': med7.pipe_labels['ner'], 'colors':col_dict}\n",
    "\n",
    "text = 'A patient was prescribed Magnesium hydroxide 400mg/5ml suspension PO of total 30ml bid for the next 5 days.'\n",
    "#text = '3. History of social phobia. 4. History of panic disorder. 5. History of polysubstance abuse. 6. Asthma. ADMISSION MEDICATIONS: The patient was not taking any prescription OTC or herbal supplements prior to admission. ALLERGIES: No known drug allergies. SOCIAL HISTORY: The patient smokes approximately 1/2 pack of cigarettes per day.'\n",
    "#text = 'Prior to her surgery, she did not have any history of cough, wheezing, orthopnea. PAST MEDICAL HISTORY: 1. Coronary artery bypass graft X 2, LIMA, AVR with bioprosthesis dated _%#MMDD2003#%_. 2. Atrial fibrillation. a. Status post pacemaker placement. b. History of Amiodarone. 3. Hypercholesterolemia. 4. No previous history of pneumonia, asthma, bronchitis or TB.'\n",
    "doc = med7(text)\n",
    "\n",
    "spacy.displacy.render(doc, style='ent', jupyter=True, options=options)\n",
    "\n",
    "[(ent.text, ent.label_) for ent in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148d28fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['medspacy_pyrush', 'medspacy_target_matcher', 'medspacy_context']\n",
      "diabetes False False False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">6. Type 2 \n",
       "<mark class=\"entity\" style=\"background: #1f77b4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CONDITION</span>\n",
       "</mark>\n",
       " mellitus. 7. Aortic stenosis. 8. Mild asthma. 9. History of atrial fibrillation. 10. History of pneumonectomy in 1999 for tuberculosis. 11. History of AV block. 12. Gastroesophageal reflux. 13. Glaucoma. 14. Hypothyroidism. 15. Osteoarthritis. 16. Osteopenia. 17. Mild pulmonary hypertension. 18. History of squamous-cell carcinoma of the left anterior thigh status post excision in 2006.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Testing medspacy for NER\n",
    "\n",
    "import medspacy\n",
    "\n",
    "from medspacy.ner import TargetRule\n",
    "from medspacy.visualization import visualize_ent, visualize_dep\n",
    "\n",
    "nlp = medspacy.load()\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "nlp.get_pipe('medspacy_target_matcher').add([TargetRule('stroke', 'CONDITION'), TargetRule('diabetes', 'CONDITION'), TargetRule('pna', 'CONDITION')])\n",
    "#doc = nlp('Patient has hx of stroke. Mother diagnosed with diabetes. No evidence of pna.')\n",
    "doc = nlp('6. Type 2 diabetes mellitus. 7. Aortic stenosis. 8. Mild asthma. 9. History of atrial fibrillation. 10. History of pneumonectomy in 1999 for tuberculosis. 11. History of AV block. 12. Gastroesophageal reflux. 13. Glaucoma. 14. Hypothyroidism. 15. Osteoarthritis. 16. Osteopenia. 17. Mild pulmonary hypertension. 18. History of squamous-cell carcinoma of the left anterior thigh status post excision in 2006.')\n",
    "#doc = nlp('4. Cystic fibrosis exacerbation: She has been on chronic antibiotics because of her severe lung disease. Will continue meropenem and tobramycin along with Zithromax and doxycycline. She will remain on Bactrim prophylaxis for possible PCP as the patient is on prednisone. In addition will continue with Vest therapy and nebs. 5. History of ABPA, on prednisone. Most likely the cause for her significant asthmatic component.')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent, ent._.is_negated, ent._.is_family, ent._.is_historical)\n",
    "medspacy.visualization.visualize_ent(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d2971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing scispacy\n",
    "\n",
    "import scispacy\n",
    "import spacy\n",
    "\n",
    "import en_core_sci_sm\n",
    "nlp = spacy.load(\"en_core_sci_sm\")\n",
    "text = \"Myeloid derived suppressor cells (MDSC) are immature myeloid cells with immunosuppressive activity. They accumulate in tumor-bearing mice and humans with different types of cancer, including hepatocellular carcinoma (HCC).\"\n",
    "doc = nlp(text)\n",
    "\n",
    "print(list(doc.sents))\n",
    "\n",
    "# Examine the entities extracted by the mention detector.\n",
    "# Note that they don't have types like in SpaCy, and they\n",
    "# are more general (e.g including verbs) - these are any\n",
    "# spans which might be an entity in UMLS, a large\n",
    "# biomedical database.\n",
    "print(doc.ents)\n",
    "\n",
    "\n",
    "# We can also visualise dependency parses\n",
    "# (This renders automatically inside a jupyter notebook!):\n",
    "from spacy import displacy\n",
    "displacy.render(next(doc.sents), style='dep', jupyter=True)\n",
    "\n",
    "# See below for the generated SVG.\n",
    "# Zoom your browser in a bit!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0dc304",
   "metadata": {},
   "source": [
    "# Testing POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b87fcd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tanobugelli/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/tanobugelli/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('patient', 'NN'),\n",
       " ('confirms', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('presence', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('pain', 'NN'),\n",
       " ('.', '.'),\n",
       " ('No', 'DT'),\n",
       " ('other', 'JJ'),\n",
       " ('symptoms', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('reported', 'VBN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTING PART OF SPEECH\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "text = \"The patient confirms the presence of pain. No other symptoms are reported.\"\n",
    "#text = \"The patient was diagnosed with depression\"\n",
    "\n",
    "# Tokenize and perform POS tagging\n",
    "tokens = word_tokenize(text)\n",
    "pos_tags = pos_tag(tokens)\n",
    "\n",
    "pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66443f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affirmative Keywords: ['are']\n",
      "Negative Keywords: ['reported']\n"
     ]
    }
   ],
   "source": [
    "# Example POS patterns for affirmative and negative contexts\n",
    "affirmative_pos_patterns = ['VB', 'VBD', 'VBG', 'VBP']  # Verbs indicating affirmation\n",
    "negative_pos_patterns = ['VB', 'VBD', 'VBG', 'VBN']  # Verbs indicating negation\n",
    "\n",
    "# Extract affirmative and negative keywords based on POS patterns\n",
    "affirmative_keywords = [word for word, pos in pos_tags if pos in affirmative_pos_patterns]\n",
    "negative_keywords = [word for word, pos in pos_tags if pos in negative_pos_patterns]\n",
    "\n",
    "print(\"Affirmative Keywords:\", affirmative_keywords)\n",
    "print(\"Negative Keywords:\", negative_keywords)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae1bb11",
   "metadata": {},
   "source": [
    "# Testing Keyword Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "332434d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context for 'depression': ['positive for neuropsych with']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#THIS GIVES WORDS PRECEEDING THE KEYWORDS\n",
    "\n",
    "\n",
    "\n",
    "from nltk import word_tokenize, ngrams\n",
    "\n",
    "# Example text\n",
    "text = \"positive for neuropsych with depression\"\n",
    "\n",
    "# Tokenize the text into a list of words\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Specify the keywords of interest\n",
    "keywords = [\"pneumonia\", \"depression\", \"fibrosis\"]\n",
    "\n",
    "# Function to extract n-grams\n",
    "def extract_ngrams(tokens, keywords, n):\n",
    "    ngram_list = list(ngrams(tokens, n)) #Generates n-grams from the list of words \n",
    "    keyword_contexts = []\n",
    "\n",
    "    for ngram in ngram_list:\n",
    "        if any(keyword in ngram for keyword in keywords):\n",
    "            # Extract words before the keyword\n",
    "            context_words = [word for word in ngram if word not in keywords]\n",
    "            keyword_contexts.append(\" \".join(context_words))\n",
    "\n",
    "    return keyword_contexts\n",
    "\n",
    "# Specify the n-gram size (number of words before the keyword)\n",
    "ngram_size = 5\n",
    "\n",
    "# Extract n-grams for each keyword\n",
    "for keyword in keywords:\n",
    "    contexts = extract_ngrams(tokens, [keyword], ngram_size)\n",
    "    if contexts:\n",
    "        print(f\"Context for '{keyword}': {contexts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa1ec7",
   "metadata": {},
   "source": [
    "# Testing Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1138cfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative context found.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Example text\n",
    "#text = \"positive for neuropsych and monkeys with depression\"\n",
    "#text = \"worked up for bananas and depression\"\n",
    "#text = \"diagnosed with a bad depression\"\n",
    "text = \"patient had no acute depression\"\n",
    "\n",
    "\n",
    "\n",
    "#NEED TO ENSURE THAT IT DOES NOT CONSIDER IF THERE'S A FULLSTOP IN BETWEEN\n",
    "\n",
    "# Define the case-insensitive patterns using regular expressions\n",
    "\n",
    "#Affirmative Case (Patient Has)\n",
    "affirmative_patterns = [\n",
    "    re.compile(r\"positive\\s+for\\s+.*?depression\", re.IGNORECASE),\n",
    "    re.compile(r\"worked\\s+up\\s+for\\s+.*?depression\", re.IGNORECASE),  \n",
    "    re.compile(r\"diagnosed\\s+with\\s+depression\", re.IGNORECASE),\n",
    "    re.compile(r\"diagnosed.*?with.*?depression\", re.IGNORECASE),\n",
    "]\n",
    "# Past Case (Patient Had)\n",
    "past_patterns = [\n",
    "    re.compile(r\"history\\s+of\\s+.*?depression\", re.IGNORECASE),\n",
    "    re.compile(r\"past\\s+medical\\s+history\\s+.*?depression\", re.IGNORECASE),\n",
    "    re.compile(r\"past\\s+history\\s+.*?depression\", re.IGNORECASE),\n",
    "    re.compile(r\"with\\s+a\\s+history\\s+of\\.*?depression\", re.IGNORECASE),\n",
    "    re.compile(r\"had previous\\s+.*?diagnosis\\s+of\\s+.*?depression\", re.IGNORECASE),  \n",
    "    re.compile(r\"childhood\\s+depression\", re.IGNORECASE),\n",
    "]\n",
    "\n",
    "#Negative Case (Patient Does Not Have)\n",
    "negative_patterns = [\n",
    "    re.compile(r\"no\\s+depression\", re.IGNORECASE),\n",
    "    re.compile(r\"no\\s+.*?depression\", re.IGNORECASE),\n",
    "]\n",
    "\n",
    "# Check if any positive pattern is present in the text\n",
    "if any(pattern.search(text) for pattern in affirmative_patterns):\n",
    "    print(\"Affirmative context found.\")\n",
    "elif any(pattern.search(text) for pattern in past_patterns):\n",
    "    print(\"Past context found.\")\n",
    "# Check if any negative pattern is present in the text\n",
    "elif any(pattern.search(text) for pattern in negative_patterns):\n",
    "    print(\"Negative context found.\")\n",
    "else:\n",
    "    print(\"No context found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c71cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
